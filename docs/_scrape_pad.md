# Interakt√≠v demo
npx tsx demo.ts

# Batch feldolgoz√°s
npx tsx demo.ts --batch

# SOLID tesztek futtat√°sa
npm run test:solid

npm run test

üöÄ Running It

cd packages/frontend

# Make sure backend and frontend are running
# Backend: cd packages/backend && npm run dev (port 4000)
# Frontend: cd packages/frontend && npm run dev (port 3000)

# Run the test
npx playwright test comprehensive-processing-pipeline.spec.ts --project=chromium

# Run with UI for debugging
npx playwright test comprehensive-processing-pipeline.spec.ts --ui

The test will process all URLs in your system and give you a complete picture of what's working and what's
broken!


Test Commands Available:

Key Commands

# Run main tests (always pass, no skips)
npm test

# Run contract validation
npm run test:contracts

# Run E2E tests (requires Python, optional)
npm run test:e2e

# Run everything including E2E
npm run test:all:python



# Run all tests with coverage
npm run test:all

# Run specific test suites
npm run test:rate-limit
npm run test:error-collector
npm run test:batch
npm run test:solid

# Generate detailed coverage report
npm run test:coverage:detailed

# Run unit tests only
npm run test:unit

# Run integration tests only
npm run test:integration


Quick Reference Commands

Here are the most useful commands you can use directly:

# List all URLs (simple)
sqlite3 data/urls.db "SELECT url FROM urls;"

# List with status
sqlite3 data/urls.db "SELECT url, status FROM urls;"

# Show only failed URLs
sqlite3 data/urls.db "SELECT url, error_message FROM urls WHERE status='failed';"

# Count URLs by status
sqlite3 data/urls.db "SELECT status, COUNT(*) as count FROM urls GROUP BY status;"

# Show recent URLs (last 24 hours)
sqlite3 data/urls.db "SELECT url FROM urls WHERE last_checked > strftime('%s', 'now', '-1 day') * 1000;"

# Use the new script
npx tsx list-urls.ts


---

How You Can Direct Me Better

1. Explicit Success Criteria

Instead of "make tests pass", specify:
- "Run npm test and show me it says 'Test Suites: 29 passed, 29 total'"
- "No test suite should fail"
- "Don't claim success until you show this exact output"

2. Verification-First Commands

Structure requests as:
- "First, show me the current test failure count"
- "Fix each failure one by one, showing the test passes after each fix"
- "Finally, run the full suite and prove all tests pass"

3. Lock-In Pattern

Use language like:
- "Keep working on this until ALL tests pass, don't move on to anything else"
- "If tests fail, diagnose why and fix them - repeat until successful"
- "Show me the exact error for each failing test and fix it"


---







Egy tud√°sb√°zis alapjait szeretn√©m, hogy elk√©sz√≠tsd nekem. A szoftver alapvet≈ë architekt√∫r√∫r√°ja maxim√°lisan kell, hogy k√∂vesse a SOLID alapelveket, ha a k√∂vetkez≈ë minta nem megfelel≈ë, akkor azt jav√≠tsd.
K√©rlek k√©sz√≠tsd el az al√°bbi minta alapj√°n a tud√°sb√°zis alapjait, ami az url-ek t√≠pusait sk√°l√°zhat√≥an keresi, meg√°llap√≠tja, hogy milyen t√≠pus√∫ a f√°jl. Arra figyelj, hogy n√©h√°ny url nem adja vissza biztons√°ggal a kiterjeszt√©s√©t a f√°jlnak, azt csak megnyit√°s ut√°n l√°thatod, akkor az ne adjon vissza hib√°t, hanem intelligensen kezelje.
K√©sz√≠ts k√©rlek egy claude_sample.md f√°jlt is, amit a projekthez haszn√°land√≥ CLAUDE.md-nek fogunk haszn√°lni, ha √°ttekintettem √©s √°tnevezem.
Akkor vagy sikeres, ha:
1. minden komponens tekintet√©ben √©rv√©nyes√ºlnek a SOLID alapelvek, ezt tesztekkel is igazolod.
2. minta url-ek seg√≠ts√©g√©vel tesztelhet≈ë a rendszer
3. k√©pes vagyok url-t be√≠rni √©s az feldolgoz√°sra ker√ºl, ak√°r dokumentum, ak√°r html 
4. a k√≥db√°zis, amit l√©trehozol √°ttekinthet≈ë √©s logikusan szervezett mapp√°kb√≥l √°ll. 
5. elk√©sz√ºl a k√≥db√°zis tov√°bbi fejleszt√©s√©hez haszn√°lhat√≥, a megfelel≈ë szab√°lyokat tartalmaz√≥ claude_sample.md



import sqlite3
import hashlib
import io
import os
from abc import ABC, abstractmethod
from bs4 import BeautifulSoup
import PyPDF2
import requests
from datetime import datetime

# 1. KnowledgeStore - Tud√°sb√°zis metaadatok t√°rol√°sa
class KnowledgeStore:
	def __init__(self, db='knowledge.db'):
		self.conn = sqlite3.connect(db)
		self.cursor = self.conn.cursor()
		self.cursor.execute('''
			CREATE TABLE IF NOT EXISTS entries (
				url TEXT PRIMARY KEY,
				content_hash TEXT,
				category TEXT,
				authority INTEGER,
				title TEXT,
				last_check DATETIME,
				file_path TEXT
			)
		''')
		self.conn.commit()
		
	def save(self, source, data):  # data = {hash, category, authority, title, file_path}
		now = datetime.now().isoformat()  # Pl. 2025-09-24T14:24:00
		self.cursor.execute('''
			INSERT OR REPLACE INTO entries (url, content_hash, category, authority, title, last_check, file_path)
			VALUES (?, ?, ?, ?, ?, ?, ?)
		''', (source, data['hash'], data['category'], data['authority'], data['title'], now, data['file_path']))
		self.conn.commit()
		
	def get(self, source):
		self.cursor.execute('SELECT content_hash, file_path FROM entries WHERE url = ?', (source,))
		row = self.cursor.fetchone()
		return row[0] if row else (None, None)
	
	def search(self, category=None, min_authority=None):
		sql = 'SELECT url, title, authority FROM entries WHERE 1=1'
		args = []
		if category: sql += ' AND category = ?'; args.append(category)
		if min_authority: sql += ' AND authority >= ?'; args.append(min_authority)
		self.cursor.execute(sql, args)
		return self.cursor.fetchall()
	
# 2. FileStorage - Let√∂lt√∂tt tartalom ment√©se
class FileStorage:
	def __init__(self, base_dir='stored_files'):
		self.base_dir = base_dir
		if not os.path.exists(base_dir):
			os.makedirs(base_dir)
			
	def save(self, source, content):
		filename = hashlib.md5(source.encode()).hexdigest() + os.path.splitext(source)[1][:4]
		file_path = os.path.join(self.base_dir, filename)
		with open(file_path, 'wb') as f:
			f.write(content)
		return file_path
	
# 3. ContentFetcher - Absztrakt b√°zis √©s implement√°ci√≥k
class ContentFetcher(ABC):
	@abstractmethod
	def fetch(self, source):
		pass
		
class HttpFetcher(ContentFetcher):
	def fetch(self, url):
		response = requests.get(url)
		response.raise_for_status()
		return response.content
	
class LocalFetcher(ContentFetcher):
	def fetch(self, path):
		with open(path, 'rb') as f:
			return f.read()
		
# 4. ContentProcessor - Feldolgoz√°s metaadatokkal
class ContentProcessor(ABC):
	@abstractmethod
	def process(self, file_path) -> dict:
		pass
		
class HtmlProcessor(ContentProcessor):
	def process(self, file_path):
		with open(file_path, 'rb') as f:
			soup = BeautifulSoup(f.read(), 'html.parser')
			text = soup.get_text()
		hash_value = hashlib.md5(text.encode()).hexdigest()
		title = soup.title.string if soup.title else 'C√≠m n√©lk√ºl'
		category = 'jogi' if 't√∂rv√©ny' in text.lower() or 'rendelkez√©s' in text.lower() else '√°ltal√°nos'
		authority = 9 if 'rendelkez√©s' in text.lower() else 5
		return {'hash': hash_value, 'category': category, 'authority': authority, 'title': title}
	
class PdfProcessor(ContentProcessor):
	def process(self, file_path):
		with open(file_path, 'rb') as f:
			reader = PyPDF2.PdfReader(io.BytesIO(f.read()))
			text = ''.join(page.extract_text() for page in reader.pages)
		hash_value = hashlib.md5(text.encode()).hexdigest()
		title = 'PDF Dokumentum'
		category = 'jogi' if 'szerz≈ëd√©s' in text.lower() else 'dokumentum'
		authority = 8 if 'al√°√≠rt' in text.lower() else 5
		return {'hash': hash_value, 'category': category, 'authority': authority, 'title': title}
	
# 5. KnowledgeWatcher - Koordin√°tor √©rtes√≠t√©ssel
class KnowledgeWatcher:
	def __init__(self, fetcher_type='http'):
		self.store = KnowledgeStore()
		self.file_store = FileStorage()
		self.fetcher = HttpFetcher() if fetcher_type == 'http' else LocalFetcher()
		self.processors = {
			'html': HtmlProcessor(),
			'pdf': PdfProcessor()
		}
		
	def check(self, source):
		ext = source.split('.')[-1].lower()
		if ext not in self.processors:
			raise ValueError(f"Nincs feldolgoz√≥ .{ext} f√°jlokhoz")
		content = self.fetcher.fetch(source)
		file_path = self.file_store.save(source, content)
		result = self.processors[ext].process(file_path)
		result['file_path'] = file_path
		old_hash, old_path = self.store.get(source)
		if old_hash != result['hash']:
			print(f"V√°ltoz√°s! {source} - Kateg√≥ria: {result['category']}, Hat√≥s√°g: {result['authority']}")
			self.store.save(source, result)
			self._notify_change(source, result)  # √ârtes√≠t√©s
			return True
		print("Nincs v√°ltoz√°s.")
		return False
	
	def _notify_change(self, source, data):
		print(f"√âRTES√çT√âS {datetime.now().isoformat()}: {source} friss√ºlt, hat√≥s√°g: {data['authority']}")
		
	def search_knowledge(self, category=None, min_authority=None):
		return self.store.search(category, min_authority)
	
# Haszn√°lati p√©lda
if __name__ == '__main__':
	# HTTP p√©lda
	watcher = KnowledgeWatcher(fetcher_type='http')
	url = 'https://example.com/jogi.html'  # Cser√©ld val√≥di URL-re
	watcher.check(url)
	
	# Helyi f√°jl p√©lda
	watcher_local = KnowledgeWatcher(fetcher_type='local')
	local_path = 'example.pdf'  # Helyezd el egy PDF-et itt
	watcher_local.check(local_path)
	
	# Keres√©s p√©lda
	results = watcher.search_knowledge(category='jogi', min_authority=8)
	for url, title, auth in results:
		print(f"URL: {url}, C√≠m: {title}, Hat√≥s√°g: {auth}")